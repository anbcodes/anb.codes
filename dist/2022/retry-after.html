<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Discovering the Retry-After header</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="/global.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Discovering the Retry-After header</h1>
</header>
<p>May 21st, 2022</p>
<p>Recently I got a job on <a
href="https://www.fiverr.com/users/anbcodes">fiverr</a> to scrape a
website. The job was to extract some data from 32K different pages.</p>
<p>I started by writing a simple Deno script that fetched a page and
extracted the data. After creating that, I put it in a loop to request
each page and save all the information to a file.</p>
<p>This appeared to be working until my script failed to parse the file
and threw a random error. I discovered that the server was returning <a
href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429">429
Too Many Requests</a>. So I added a check to wait 20 seconds then try to
continue requesting the pages.</p>
<p>This worked, but it wasn't the most efficient because I had just
guessed 20 seconds and did not know how long the server needed me to
wait. I ended up increasing it to 60 seconds because that appeared to
always work: the next request was always able to get through.</p>
<p>I let this run for a while, but later stumbled apon the Retry-After
header after doing some research about rate limiting. From <a
href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After">MDN</a></p>
<blockquote>
<p>The Retry-After response HTTP header indicates how long the user
agent should wait before making a follow-up request.</p>
</blockquote>
<p>It was perfect because I needed to know the amount of time to wait
before retrying the request! So I added it into my script, and I think
it ended up saving about 2-3 hours.</p>
<p>If you have a comment - email me at <a
href="mailto:comments@anb.codes"
class="email">comments@anb.codes</a></p>
<p>This work is licensed under the <a
href="http://creativecommons.org/licenses/by/4.0/">Creative Commons
Attribution 4.0 International License.</a></p>
<p><a href="/">Home</a></p>
</body>
</html>
